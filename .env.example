# LLM Configuration
LLM_PROVIDER=ollama  # or "openai"
LLM_MODEL=llama3.1:8b  # or "gpt-4o" for OpenAI
LLM_TEMPERATURE=0.1
LLM_BASE_URL=http://localhost:11434  # Ollama base URL
OPENAI_API_KEY=  # Required if LLM_PROVIDER=openai

# Embedding Configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Vector Store Configuration
VECTOR_STORE_TYPE=in_memory  # Options: in_memory, chroma, pinecone

# ChromaDB Configuration (when VECTOR_STORE_TYPE=chroma)
CHROMA_COLLECTION_NAME=evidencing_agent
CHROMA_PERSIST_DIRECTORY=data/chroma  # Set to empty for in-memory

# Pinecone Configuration (when VECTOR_STORE_TYPE=pinecone)
PINECONE_API_KEY=  # Your Pinecone API key
PINECONE_INDEX_NAME=evidencing-agent
PINECONE_ENVIRONMENT=  # e.g., us-west1-gcp
PINECONE_NAMESPACE=default

# Database (for structured data: commitments, decisions, feedback metadata)
DATABASE_PATH=data/evidencing.db

# RAG Configuration
RAG_CHUNK_SIZE=512
RAG_CHUNK_OVERLAP=50
RAG_TOP_K=3

# Feedback Retrieval
FEEDBACK_TOP_K=5
SIMILARITY_THRESHOLD=0.70

# Confidence Thresholds
CONFIDENCE_HIGH_THRESHOLD=0.85
CONFIDENCE_MEDIUM_THRESHOLD=0.70
CONFIDENCE_LOW_THRESHOLD=0.50

# Telemetry
ENABLE_TELEMETRY=true
